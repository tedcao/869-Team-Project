{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9804ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import scipy\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccf2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c12e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeks = pd.read_csv(\"greeks.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "data = pd.read_csv(\"train.csv\", index_col='Id')\n",
    "data.columns = data.columns.str.replace(' ', '')\n",
    "test_data.columns = test_data.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "94f6dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data in line chart\n",
    "feature_names = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BN', 'BQ', 'BR', 'BZ', 'CB', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DV', 'DY', 'EB', 'EE', 'EG', 'EH', 'EP', 'EU', 'FE', 'FI', 'FR', 'GB', 'GE', 'GF', 'GH', 'GI']\n",
    "# feature_names = ['AB']\n",
    "\n",
    "def lineChart(feature_name):\n",
    "    feature_data = data[feature_name].to_numpy()\n",
    "    plt.plot(feature_data)\n",
    "    plt.show()\n",
    "\n",
    "# remove the outliers using IQR logic\n",
    "def removeOutliers(feature_data):\n",
    "    # print(feature_data)\n",
    "    mean = np.mean(feature_data)\n",
    "    #print(mean)\n",
    "    q1, q3 = np.percentile(feature_data, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    outliers = [x for x in feature_data if x < lower_bound or x > upper_bound]\n",
    "    feature_data_replaced = [mean if x < lower_bound or x > upper_bound else x for x in feature_data]\n",
    "    #print(\"The count of outliers are:\", len(outliers))\n",
    "    # print(\"The data with replaced outliers is:\", feature_data_replaced)\n",
    "    return feature_data_replaced\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    # lineChart(feature_name)\n",
    "    feature_data = data[feature_name]\n",
    "    feature_data_new = removeOutliers(feature_data)\n",
    "    # print(len(feature_data), len(feature_data_new))\n",
    "    data[feature_name] = feature_data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df91eb7",
   "metadata": {},
   "source": [
    "# convert 'EJ' to a categorical variable, create onehot encoded columns\n",
    "one_hot_encoded = pd.get_dummies(data['EJ']).add_prefix('EJ_')\n",
    "df_encoded = pd.concat([data, one_hot_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a230e",
   "metadata": {},
   "source": [
    "df_encoded = df_encoded.drop('EJ', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524a431",
   "metadata": {},
   "source": [
    "data = df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ebe60404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null columns with mean\n",
    "numeric_col = [column for column in data.columns if column not in ['Id', 'EJ', 'Class']]\n",
    "# Prepare the data - encode, remove inf, -inf and fill NaNs\n",
    "for column in numeric_col:\n",
    "    data[column] = data[column].replace([np.inf, -np.inf], np.nan)\n",
    "    data[column] = data[column].fillna(data[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "223a73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes based on the target variable\n",
    "majority_class = data[data['Class'] == 0]\n",
    "minority_class_1 = data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9700f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the minority classes\n",
    "minority_class_upsampled_1 = resample(minority_class_1,\n",
    "                                      replace=True,\n",
    "                                      n_samples=len(majority_class),\n",
    "                                      random_state=42)\n",
    "\n",
    "\n",
    "# Concatenate the upsampled minority classes with the majority class\n",
    "df_upsampled = pd.concat([majority_class, minority_class_upsampled_1])\n",
    "\n",
    "data = df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0d255e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data - encode, remove inf, -inf and fill NaNs\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = data[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dfb6ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [column for column in data.columns if column not in ['Id', 'Class']]\n",
    "target = 'Class'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136aecbd",
   "metadata": {},
   "source": [
    "#### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a060c3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Random Forest to get feature importances\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(data[features], data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "994db09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ddf30eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features\n",
    "top_features = feature_importances['Feature'][:30].append(feature_importances['Feature'][53:54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "320a52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "46709092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b6da4085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss scores for each fold: [0.19507062 0.24395133 0.18546459 0.20514245 0.23890138]\n",
      "Average Log Loss: 0.2137060746529642\n"
     ]
    }
   ],
   "source": [
    "# Model Definition with RandomForest and Cross-validation\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=5, random_state=42)\n",
    "scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='neg_log_loss')\n",
    "log_loss_scores = -scores\n",
    "print(f'Log Loss scores for each fold: {log_loss_scores}')\n",
    "average_log_loss = np.mean(log_loss_scores)\n",
    "print(f'Average Log Loss: {average_log_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4f2cdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ece8c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (Log Loss):\n",
      "[0.00880142 0.07640653 0.02517437 0.10919002 0.03238571 0.07740026\n",
      " 0.01107517 0.06854812 0.07920504 0.00893975]\n",
      "Average Log Loss Score: 0.049712639272142964\n"
     ]
    }
   ],
   "source": [
    "# Define the LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(objective='binary', metric='binary_logloss', reg_lambda=0.3) # reg_alpha=0.2,\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Define the scorer as log loss\n",
    "scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "# Perform cross-validation and calculate the scores\n",
    "scores = cross_val_score(lgb_model, X_train_scaled, y_train, cv=cv, scoring=scorer)\n",
    "scores = -scores\n",
    "\n",
    "# Calculate the average score\n",
    "avg_score = np.mean(scores)\n",
    "\n",
    "print(\"Cross-Validation Scores (Log Loss):\")\n",
    "print(scores)\n",
    "print(\"Average Log Loss Score:\", avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "56222459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(metric='binary_logloss', objective='binary', reg_lambda=0.3)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with the training data\n",
    "lgb_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9a568a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "test_data_clean = test_data[features]\n",
    "test_data_clean = test_data_clean.replace([np.inf, -np.inf], np.nan)\n",
    "test_data_clean.fillna(test_data_clean.median(numeric_only=True), inplace=True)\n",
    "test_data_clean['EJ'] = test_data_clean['EJ'].astype('category').cat.codes\n",
    "test_data_scaled = scaler.transform(test_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fb3ddb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions using the fitted model\n",
    "test_preds = lgb_model.predict_proba(test_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "368fdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file\n",
    "submission = pd.DataFrame(test_data['Id'], columns=['Id'])\n",
    "submission[['class_0', 'class_1']] = test_preds\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0c11f64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.75089</td>\n",
       "      <td>0.24911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.75089</td>\n",
       "      <td>0.24911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.75089</td>\n",
       "      <td>0.24911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.75089</td>\n",
       "      <td>0.24911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.75089</td>\n",
       "      <td>0.24911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  class_0  class_1\n",
       "0  00eed32682bb  0.75089  0.24911\n",
       "1  010ebe33f668  0.75089  0.24911\n",
       "2  02fa521e1838  0.75089  0.24911\n",
       "3  040e15f562a2  0.75089  0.24911\n",
       "4  046e85c7cc7f  0.75089  0.24911"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad1d7840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (Log Loss):\n",
      "[-0.10276949 -0.04446035 -0.065472   -0.0652326  -0.08916046]\n",
      "Average Log Loss Score: -0.07341897996701433\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "\n",
    "\n",
    "# Define the base XGBoost model\n",
    "base_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "# Wrap the base model with MultiOutputClassifier\n",
    "#model = MultiOutputClassifier(base_model)\n",
    "\n",
    "# Define the scorer as log loss\n",
    "scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "# Perform cross-validation and calculate the scores\n",
    "scores = cross_val_score(base_model, X_train_scaled, y_train, scoring=scorer)#cv=5,\n",
    "\n",
    "# Calculate the average score\n",
    "avg_score = np.mean(scores)\n",
    "\n",
    "print(\"Cross-Validation Scores (Log Loss):\")\n",
    "print(scores)\n",
    "print(\"Average Log Loss Score:\", avg_score)\n",
    "#try lgbm without the minus before scorer tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "85ca7a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with the training data\n",
    "base_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "36834ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions using the fitted model\n",
    "test_preds = base_model.predict_proba(test_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e4f9f05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4411614, 0.5588386],\n",
       "       [0.4411614, 0.5588386],\n",
       "       [0.4411614, 0.5588386],\n",
       "       [0.4411614, 0.5588386],\n",
       "       [0.4411614, 0.5588386]], dtype=float32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a98b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
